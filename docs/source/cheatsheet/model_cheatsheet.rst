Model Cheatsheet
===================

GNN Cheatsheet 
----------------
.. list-table::
    :header-rows: 0
    :class: custom-table

    * - GAT
      - The GAT (Graph Attention Network) model, based on the `"Graph Attention Networks" <https://arxiv.org/abs/1710.10903>`__ paper.
    * - GCN
      - The GCN (Graph Convolutional Network) model, based on the `"Semi-supervised Classification with Graph Convolutional Networks" <https://arxiv.org/abs/1609.02907>`__ paper.
    * - HAN
      - The Heterogeneous Graph Attention Network (HAN) model, as introduced in the `"Heterogeneous Graph Attention Network" <https://arxiv.org/abs/1903.07293>`__ paper.
    * - OGC
      - The OGC method from the `"From Cluster Assumption to Graph Convolution: Graph-based Semi-Supervised Learning Revisited" <https://arxiv.org/abs/2309.13599>`__ paper.
    * - HGT
      - The Heterogeneous Graph Transformer (HGT) model, as introduced in the `"Heterogeneous Graph Transformer" <https://arxiv.org/abs/2003.01332>`__ paper.
    * - SAGE
      - The SAGE model, as introduced in the `"Inductive Representation Learning on Large Graphs" <https://arxiv.org/abs/1706.02216>`__ paper.
    * - RECT_L
      - The RECT model, or more specifically its supervised part RECT-L, from the `"Network Embedding with Completely-imbalanced Labels" <https://arxiv.org/abs/2007.03545>`__ paper.
    * - Label-Free-GNN
      - Two classic methods (Random and VertexCover) and PS-FeatProp-W from the `"Label-free Node Classification on Graphs with Large Language Models (LLMS)" <https://arxiv.org/abs/2310.04668>`__ paper.
    * - TAPE
      - The TAPE method from the `"Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning" <https://arxiv.org/abs/2305.19523>`__ paper.



TNN Cheatsheet
----------------
.. list-table::
    :header-rows: 0
    :class: custom-table

    * - FTTransformer
      - The FT-Transformer model introduced in the `"Revisiting Deep Learning Models for Tabular Data" <https://arxiv.org/abs/2106.11959>`_ paper.
    * - TabTransformer
      - The Tab-Transformer model introduced in the `"TabTransformer: Tabular Data Modeling Using Contextual Embeddings" <https://arxiv.org/abs/2012.06678>`_ paper.
    * - TabNet
      - The TabNet model introduced in the `"TabNet: Attentive Interpretable Tabular Learning" <https://arxiv.org/abs/1908.07442>`_ paper.
    * - ExcelFormer
      - The ExcelFormer model introduced in the `"ExcelFormer: A neural network surpassing GBDTs on tabular data" <https://arxiv.org/abs/2301.02819>`_ paper.
    * - Trompt
      - The Trompt model introduced in the `"Trompt: Towards a Better Deep Neural Network for Tabular Data" <https://arxiv.org/abs/2305.18446>`_ paper.


RTL Cheatsheet
-----------------------

.. list-table::
    :header-rows: 0
    :class: custom-table

    * - BRIDGE
      - The BRIDGE method from the `"rLLM: Relational Table Learning with LLMs" <https://arxiv.org/abs/2407.20157>`_ paper.
